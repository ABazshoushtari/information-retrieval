{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f40d92a-276e-4302-9b8b-98d4693f5cde",
   "metadata": {},
   "source": [
    "# Information Retrieval Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb7521-e948-4764-bb12-ca704e7444c6",
   "metadata": {},
   "source": [
    "#### Ali Bazshoushtari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2531301f-0977-45d2-a034-b08b59f9a363",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072d5bc-c348-41eb-8f4d-45f7a85279d5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08389154",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:23:54.993195800Z",
     "start_time": "2024-06-28T22:23:53.987742200Z"
    }
   },
   "outputs": [],
   "source": [
    "import parsivar\n",
    "from string import punctuation\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe1f4c-1f1a-436f-b189-dd2452118b15",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd69437-5843-4269-b95d-3dda17df4464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:23:58.965399500Z",
     "start_time": "2024-06-28T22:23:58.953605100Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_docs(): \n",
    "    docs = {}\n",
    "    contents = []\n",
    "    urls = []\n",
    "    with open(\"IR_data_news_12k.json\", 'r') as file:\n",
    "        articles = json.load(file)\n",
    "        for doc_id in articles.keys():\n",
    "            # index of files\n",
    "            index = str(doc_id)\n",
    "            # extract and save url, title and content of each doc\n",
    "            docs[index] = {'title': articles[index]['title'],\n",
    "                             'content': articles[index]['content'],\n",
    "                             'url': articles[index]['url'],\n",
    "                            }\n",
    "            articles[index].pop('tags')\n",
    "            articles[index].pop('date')\n",
    "            articles[index].pop('category')\n",
    "            \n",
    "            contents.append(docs[index]['content'])\n",
    "            urls.append(docs[index]['url'])\n",
    "    return docs, contents, urls, articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52230e8-6b2b-4d9c-8c47-9c7f040fa795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:24:00.918947400Z",
     "start_time": "2024-06-28T22:23:59.927551700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'اعلام زمان قرعه کشی جام باشگاه های فوتسال آسیا', 'content': '\\nبه گزارش خبرگزاری فارس، کنفدراسیون فوتبال آسیا (AFC) در نامه ای رسمی به فدراسیون فوتبال ایران و باشگاه گیتی پسند زمان\\xa0 قرعه کشی جام باشگاه های فوتسال آسیا را رسماً اعلام کرد. بر این اساس 25 فروردین ماه 1401 مراسم قرعه کشی جام باشگاه های فوتسال آسیا در مالزی برگزار می شود. باشگاه گیتی پسند بعنوان قهرمان فوتسال ایران در سال 1400 به این مسابقات راه پیدا کرده است. پیش از این گیتی پسند تجربه 3 دوره حضور در جام باشگاه های فوتسال آسیا را داشته که هر سه دوره به فینال مسابقات راه پیدا کرده و یک عنوان قهرمانی و دو مقام دومی بدست آورده است. انتهای پیام/\\n\\n\\n', 'url': 'https://www.farsnews.ir/news/14001224001005/اعلام-زمان-قرعه-کشی-جام-باشگاه-های-فوتسال-آسیا'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'اعلام زمان قرعه کشی جام باشگاه های فوتسال آسیا',\n",
       " 'content': '\\nبه گزارش خبرگزاری فارس، کنفدراسیون فوتبال آسیا (AFC) در نامه ای رسمی به فدراسیون فوتبال ایران و باشگاه گیتی پسند زمان\\xa0 قرعه کشی جام باشگاه های فوتسال آسیا را رسماً اعلام کرد. بر این اساس 25 فروردین ماه 1401 مراسم قرعه کشی جام باشگاه های فوتسال آسیا در مالزی برگزار می شود. باشگاه گیتی پسند بعنوان قهرمان فوتسال ایران در سال 1400 به این مسابقات راه پیدا کرده است. پیش از این گیتی پسند تجربه 3 دوره حضور در جام باشگاه های فوتسال آسیا را داشته که هر سه دوره به فینال مسابقات راه پیدا کرده و یک عنوان قهرمانی و دو مقام دومی بدست آورده است. انتهای پیام/\\n\\n\\n',\n",
       " 'url': 'https://www.farsnews.ir/news/14001224001005/اعلام-زمان-قرعه-کشی-جام-باشگاه-های-فوتسال-آسیا'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs, contents, urls, articles = read_docs()\n",
    "print(docs['0'])\n",
    "articles['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e189da-e80d-417c-bcb9-5530d0c95399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:24:01.884081300Z",
     "start_time": "2024-06-28T22:24:01.875595500Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class DataNormalization:\n",
    "    def __init__(self):\n",
    "        # pattern for matching mi in start of token\n",
    "        self.mi_patterns = r\"\\bن?می[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+\"\n",
    "        \n",
    "        # punctuation marks\n",
    "        self.punc_after = r\"\\.:!،؛؟»\\]\\)\\}\"\n",
    "        self.punc_before = r\"«\\[\\(\\{\"\n",
    "        self.all_punc_marks = r\"[\\.:!،؛؟»\\'\\]\\)\\}|«\\[\\(\\/\\{><+\\-?!=_]\"\n",
    "\n",
    "        self.number_not_persian = \"0123456789%٠١٢٣٤٥٦٧٨٩\"\n",
    "        self.number_persian = \"۰۱۲۳۴۵۶۷۸۹٪۰۱۲۳۴۵۶۷۸۹\"\n",
    "        \n",
    "        # fathe kasre ,....\n",
    "        self.arabic_patterns = [\n",
    "                    (\"[\\u064b\\u064c\\u064d\\u064e\\u064f\\u0650\\u0651\\u0652]\", \"\"),\n",
    "                ]\n",
    "        \n",
    "        self.punctuation_spacing_patterns = [\n",
    "                # remove space before and after quotation\n",
    "                ('\" ([^\\n\"]+) \"', r'\"\\1\"'),\n",
    "                (\" ([\" + self.punc_after + \"])\", r\"\\1\"),  # remove space before\n",
    "                (\"([\" + self.punc_before + \"]) \", r\"\\1\"),  # remove space after\n",
    "                # put space after . and :\n",
    "                (\n",
    "                    \"([\" + self.punc_after[:3] + \"])([^ \" + self.punc_after + r\"\\d۰۱۲۳۴۵۶۷۸۹])\",\n",
    "                    r\"\\1 \\2\",\n",
    "                ),\n",
    "                (\n",
    "                    \"([\" + self.punc_after[3:] + \"])([^ \" + self.punc_after + \"])\",\n",
    "                    r\"\\1 \\2\",\n",
    "                ),  # put space after\n",
    "                (\n",
    "                    \"([^ \" + self.punc_before + \"])([\" + self.punc_before + \"])\",\n",
    "                    r\"\\1 \\2\",\n",
    "                ),  # put space before\n",
    "                # put space after number\n",
    "                (r\"(\\d)([آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی])\", r\"\\1 \\2\"),\n",
    "                # put space before number\n",
    "                (r\"([آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی])(\\d)\", r\"\\1 \\2\"),\n",
    "            ]\n",
    "        \n",
    "        # extra space patterns\n",
    "        self.extra_space_patterns = [\n",
    "            (r\" {2,}\", \" \"),           # remove extra spaces\n",
    "            (r\"\\n{3,}\", \"\\n\\n\"),       # remove extra newlines\n",
    "            (r\"\\u200c{2,}\", \"\\u200c\"), # remove extra ZWNJs\n",
    "            (r\"\\u200c{1,} \", \" \"),     # remove unneeded ZWNJs before space\n",
    "            (r\" \\u200c{1,}\", \" \"),     # remove unneeded ZWNJs after space\n",
    "            (r\"\\b\\u200c*\\B\", \" \"),      # remove unneeded ZWNJs at the beginning of words\n",
    "            (r\"\\B\\u200c*\\b\", \" \"),      # remove unneeded ZWNJs at the end of words\n",
    "            (r\"[ـ\\r]\", \" \"),           # remove keshide, carriage returns\n",
    "        ]\n",
    "\n",
    "        self.spacing_patterns = [\n",
    "            (r\"\\xa0\",\" \"),  # remove no-break char\n",
    "            (r\"([^ ]) ی \", r\"\\1‌ی \"),          # fix 'ی' space\n",
    "            (r\"(^| )(ن?می) \", r\"\\1\\2‌\"),        # fix 'می' and 'نمی' space. put ZWNJ after them\n",
    "            # put zwnj before تر, تری, ترین, گر, گری, ها, های\n",
    "            (r\"(?<=[^\\n\\d\" + self.punc_after + self.punc_before + r\"]{2}) (تر(ین?)?|گری?|های?)(?=[ \\n\" + self.punc_after + self.punc_before + r\"]|$)\", r\"‌\\1\"),\n",
    "            # fix suffix spacing ام, ایم, اش, اند, ای, اید, ات\n",
    "            (r\"([^ ]ه) (ا(م|یم|ش|ند|ی|ید|ت))(?=[ \\n\" + self.punc_after + r\"]|$)\", r\"\\1‌\\2\"),  # fix verb conjugation spacing\n",
    "            (r\"(ه)(ها)\", r\"\\1‌\\2\"),  \n",
    "        ]\n",
    "\n",
    "        # some special unicodes which should be replaced by persian terms\n",
    "        self.unicode_replacements = [\n",
    "                    (\"﷽\",\" بسم الله الرحمن الرحیم \"),\n",
    "                    ('ﷻ', \"الله-جل-جلاله\"),\n",
    "                    ('ﷺ', \"صلی-الله-علیه-وسلم\"),\n",
    "                    (\" ﷼\", \" ریال\"),\n",
    "                    (\"(ﷰ|ﷹ)\", \" صلی \"),\n",
    "                    (\" ﷲ\", \" الله\"),\n",
    "                    (\" ﷳ\", \" اکبر\"),\n",
    "                    (\" ﷴ\", \" محمد\"),\n",
    "                    (\" ﷵ\", \" صلعم\"),\n",
    "                    (\" ﷶ\", \" رسول\"),\n",
    "                    (\" ﷷ\", \" علیه\"),\n",
    "                    (\" ﷸ\", \" وسلم\"),\n",
    "                    (\" ﻵ|ﻶ|ﻷ|ﻸ|ﻹ|ﻺ|ﻻ|ﻼ\", \" لا\"),\n",
    "                    (\"آ\", \"ا\"),\n",
    "                    ('أ', 'ا'),\n",
    "                    ('ٱ', 'ا'),\n",
    "                    ('إ', 'ا'),\n",
    "                    ('ك','ک'),\n",
    "                    ('ي','ی'),\n",
    "                    ('ئ', 'ی'),\n",
    "                    ('یٰ', 'ی'),\n",
    "                    ('هٔ','ه'),\n",
    "                    ('ؤ', 'و'),\n",
    "                    ('%', \"درصد\"),\n",
    "                    ('٪', \"درصد\")\n",
    "                ]\n",
    "        \n",
    "        \n",
    "        # bons of verbs\n",
    "        with Path('verbs.dat').open(encoding=\"utf8\") as verbs_file:\n",
    "                verbs = list(\n",
    "                    reversed([verb.strip() for verb in verbs_file if verb]),\n",
    "                )\n",
    "                self.present_bons = {verb[1:].split(\"#\")[0].strip() for verb in verbs[1:]}\n",
    "                self.past_bons = {verb.split(\"#\")[1] for verb in verbs}\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def regex_replace(patterns: list, text: str) -> str:\n",
    "        for pattern, repl in patterns:\n",
    "            text = re.sub(pattern, repl, text)\n",
    "        return text\n",
    "\n",
    "    # fix spacings\n",
    "    def spacing_correction(self, text: str) -> str:\n",
    "        text = self.regex_replace(self.extra_space_patterns, text)\n",
    "        text = self.regex_replace(self.punctuation_spacing_patterns, text)\n",
    "        text = self.regex_replace(self.spacing_patterns, text)\n",
    "        return text\n",
    "\n",
    "    # replace special characters\n",
    "    def unicode_replacement(cls, text: str) -> str:\n",
    "        for old, new in cls.unicode_replacements:\n",
    "            text = re.sub(old, new, text)\n",
    "        return text\n",
    "\n",
    "\n",
    "    # remove punctuation marks\n",
    "    def remove_punc_marks(cls, text: str) -> str:\n",
    "        return re.sub(cls.all_punc_marks, \"\", text)        \n",
    "     \n",
    "    # remove some arabic chars\n",
    "    def remove_arabic_chars(cls, text: str) -> str:\n",
    "        return cls.regex_replace(cls.arabic_patterns, text)\n",
    "\n",
    "    \n",
    "    # remove punctuation marks and arabic chars\n",
    "    def remove_special_chars(cls, text: str) -> str:\n",
    "        text = cls.remove_punc_marks(text)\n",
    "        text = cls.remove_arabic_chars(text)\n",
    "        return text\n",
    "    \n",
    "    # convert numbers to persian numbers\n",
    "    def persian_number(cls, text: str) -> str:\n",
    "        translation_table = str.maketrans(\n",
    "            cls.number_not_persian,\n",
    "            cls.number_persian )\n",
    "        translated_text = text.translate(translation_table)\n",
    "        return translated_text\n",
    "\n",
    "    # seperate mi in start of verbs\n",
    "    def seperate_mi(cls, text:str) -> str:\n",
    "        matches = re.findall(cls.mi_patterns, text)\n",
    "        for m in matches:\n",
    "            r = re.sub(\"^(ن?می)\", r\"\\1‌\", m)\n",
    "            # remove mi from token to check it contains the bon of a verb or not\n",
    "            x = re.sub(\"^(ن?می)\", \"\", m)\n",
    "            for verb in cls.present_bons:\n",
    "                if verb in x:\n",
    "                    text = text.replace(m, r)\n",
    "            for verb in cls.past_bons:\n",
    "                if verb in x:\n",
    "                    text = text.replace(m, r)\n",
    "        return text\n",
    "\n",
    "    # general normalization method to perform all above functions\n",
    "    def normalize(cls, text:str) -> str:\n",
    "        text = cls.remove_special_chars(text)\n",
    "        text = cls.seperate_mi(text)\n",
    "        text = cls.persian_number(text)\n",
    "        text = cls.unicode_replacement(text)\n",
    "        text = cls.spacing_correction(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38522f1-1656-4544-9db8-05508685b572",
   "metadata": {},
   "source": [
    "## Normalization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1229b125-90c1-487f-a99e-c81f818a4e49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:24:03.133376600Z",
     "start_time": "2024-06-28T22:24:03.099490800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "می‌رفتم می‌رفتم\n",
      "به نام‌های خدا‌ی درباره‌ی مهربان‌ترین\n",
      "به نام‌های الله خدا‌ی ۹۹ درصد درباره‌ی سلام ییی مقابله ا بسم الله الرحمن الرحیم مهربان بسم الله الرحمن الرحیم‌ترین\n",
      "ازمون رفت العین التی تمتل بک لن تنظر لغیرک\n",
      "ابق قویا خاله فقصتک لم تنتهی بعد \n"
     ]
    }
   ],
   "source": [
    "normalizer = DataNormalization()\n",
    "print(normalizer.seperate_mi(\"میرفتم میرفتم\"))\n",
    "print(normalizer.spacing_correction(\"به نام های خدا‌ ی  درباره ی مهربان ترین\"))\n",
    "print(normalizer.normalize(\"به نام های  ﷲ خدا‌ ی 99 % درباره ی ً ٌ ٍسلامَ ُ ِ ّ ْ+ئئئ  مقابله أ ﷽مهربان >. ﷽  . ترین\"))\n",
    "print(normalizer.normalize(\"«آزمون! رفت ? العين التي تمتل بك لن تنظر لغيرك...»\"))\n",
    "print(normalizer.normalize(\"'ابقَ قویّا، خالهٔ فَقِصّتُکَ لم تَنتَهی بعد ..' \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e0a7b-72a9-4c5f-b503-b000b2901b49",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e520ef33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:24:04.314027900Z",
     "start_time": "2024-06-28T22:24:04.295384300Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    top_k = {}\n",
    "    pattern = re.compile(r'([؟!?]+|[\\d.:]+|[:.،؛»\\])}\"«\\[({/\\\\])')\n",
    "    after_verbs = {\n",
    "                \"ام\",\n",
    "                \"ای\",\n",
    "                \"است\",\n",
    "                \"ایم\",\n",
    "                \"اید\",\n",
    "                \"اند\",\n",
    "                \"بودم\",\n",
    "                \"بودی\",\n",
    "                \"بود\",\n",
    "                \"بودیم\",\n",
    "                \"بودید\",\n",
    "                \"بودند\",\n",
    "                \"باشم\",\n",
    "                \"باشی\",\n",
    "                \"باشد\",\n",
    "                \"باشیم\",\n",
    "                \"باشید\",\n",
    "                \"باشند\",\n",
    "                   \"شده\",\n",
    "            \"نشده\",\n",
    "                \"شوم\",\n",
    "                \"شوی\",\n",
    "                \"شود\",\n",
    "                \"شویم\",\n",
    "                \"شوید\",\n",
    "                \"شوند\",\n",
    "                \"شدم\",\n",
    "                \"شدی\",\n",
    "                \"شد\",\n",
    "                \"شدیم\",\n",
    "                \"شدید\",\n",
    "                \"شدند\",\n",
    "                \"نشوم\",\n",
    "                \"نشوی\",\n",
    "                \"نشود\",\n",
    "                \"نشویم\",\n",
    "                \"نشوید\",\n",
    "                \"نشوند\",\n",
    "                \"نشدم\",\n",
    "                \"نشدی\",\n",
    "                \"نشد\",\n",
    "                \"نشدیم\",\n",
    "                \"نشدید\",\n",
    "                \"نشدند\",\n",
    "                \"می‌شوم\",\n",
    "                \"می‌شوی\",\n",
    "                \"می‌شود\",\n",
    "                \"می‌شویم\",\n",
    "                \"می‌شوید\",\n",
    "                \"می‌شوند\",\n",
    "                \"می‌شدم\",\n",
    "                \"می‌شدی\",\n",
    "                \"می‌شد\",\n",
    "                \"می‌شدیم\",\n",
    "                \"می‌شدید\",\n",
    "                \"می‌شدند\",\n",
    "                \"نمی‌شوم\",\n",
    "                \"نمی‌شوی\",\n",
    "                \"نمی‌شود\",\n",
    "                \"نمی‌شویم\",\n",
    "                \"نمی‌شوید\",\n",
    "                \"نمی‌شوند\",\n",
    "                \"نمی‌شدم\",\n",
    "                \"نمی‌شدی\",\n",
    "                \"نمی‌شد\",\n",
    "                \"نمی‌شدیم\",\n",
    "                \"نمی‌شدید\",\n",
    "                \"نمی‌شدند\",\n",
    "               \n",
    "            }\n",
    "\n",
    "    before_verbs = {\n",
    "                \"خواهم\",\n",
    "                \"خواهی\",\n",
    "                \"خواهد\",\n",
    "                \"خواهیم\",\n",
    "                \"خواهید\",\n",
    "                \"خواهند\",\n",
    "                \"نخواهم\",\n",
    "                \"نخواهی\",\n",
    "                \"نخواهد\",\n",
    "                \"نخواهیم\",\n",
    "                \"نخواهید\",\n",
    "                \"نخواهند\",\n",
    "            }\n",
    "    \n",
    "    def __init__(self):\n",
    "        # save terms like گفته ، خورده which are bon mazi + ه\n",
    "        with Path('verbs.dat').open(encoding=\"utf8\") as verbs_file:\n",
    "                verbs = list(\n",
    "                    reversed([verb.strip() for verb in verbs_file if verb]),\n",
    "                )\n",
    "                DataPreprocessing.verbe = {(verb.split(\"#\")[0] + 'ه') for verb in verbs}\n",
    "     \n",
    "     \n",
    "    # Remove Punctuations\n",
    "    @staticmethod\n",
    "    def Remove_Punctuations(text):\n",
    "        return re.sub(f'[{punctuation}؟،٪×÷»«]+', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    @staticmethod\n",
    "    def Tokenization(text):\n",
    "        text = DataPreprocessing.pattern.sub(r\" \\1 \", text.replace(\"\\n\", \" \").replace(\"\\t\", \" \"))\n",
    "        tokens = [word for word in text.split(\" \") if word]\n",
    "        tokens_cleaned = [token.strip('\\xa0') for token in tokens if len(token.strip()) != 0]\n",
    "\n",
    "        result = [\"\"]\n",
    "        # merge multi term verbs like خواهم رفت to خواهم_رفت\n",
    "        for token in reversed(tokens_cleaned):\n",
    "            if token in DataPreprocessing.before_verbs or (\n",
    "                result[-1] in DataPreprocessing.after_verbs and token in DataPreprocessing.verbe\n",
    "            ):\n",
    "                result[-1] = token + \"_\" + result[-1]\n",
    "            else:\n",
    "                result.append(token)\n",
    "        return list(reversed(result[1:]))\n",
    "    \n",
    "    # method to tokenize a text\n",
    "    def tokenize(self, text):\n",
    "        return self.Tokenization(text)\n",
    "    \n",
    "    # Normalization\n",
    "    @staticmethod\n",
    "    def Normalization(text):\n",
    "        my_normalizer = DataNormalization()\n",
    "        return my_normalizer.normalize(text)\n",
    "    \n",
    "    # Stemming\n",
    "    @staticmethod\n",
    "    def Stemming(tokens):\n",
    "        stemmed = []\n",
    "        my_stemmer = parsivar.FindStems()\n",
    "        for token in tokens:\n",
    "            stemmed.append(my_stemmer.convert_to_stem(token))\n",
    "        return stemmed\n",
    "    \n",
    "    # Stop_Words\n",
    "    @staticmethod\n",
    "    def Top_K_Frequent(tokens,k):\n",
    "        token_counts = Counter(tokens)\n",
    "        sorted_tokens = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        stopwords_to_remove = [token for token, count in sorted_tokens[:k]]\n",
    "        report = {token: count for token, count in sorted_tokens[:k]}\n",
    "        return report\n",
    "        \n",
    "    # print top k frequent terms\n",
    "    def print_top_k(self):\n",
    "        for token, count in self.top_k.items():\n",
    "            print(f\"Token: {token}, Count: {count}\")\n",
    "            \n",
    "\n",
    "    # preprocess a text and return final tokens\n",
    "    def simple_preprocess(self, content):\n",
    "        punctuated_content = self.Remove_Punctuations(content)\n",
    "        normalized_content = self.Normalization(punctuated_content)\n",
    "        tokens_of_a_sentence = self.Tokenization(normalized_content)\n",
    "        final_tokens_of_a_sentence = self.Stemming(tokens_of_a_sentence)\n",
    "        tokens = [token for token in final_tokens_of_a_sentence if token not in self.top_k]\n",
    "        return tokens\n",
    "        \n",
    "\n",
    "    # preprocess all given docs\n",
    "    def preprocess(self, docs, k=50):\n",
    "        tokens = []\n",
    "        counter = 0\n",
    "        for idx in docs.keys():\n",
    "            content = docs[str(idx)]['content']\n",
    "            punctuated_content = self.Remove_Punctuations(content)            \n",
    "            normalized_content = self.Normalization(punctuated_content)\n",
    "            all_tokens = self.Tokenization(normalized_content)\n",
    "            stemmed_tokens = self.Stemming(all_tokens)\n",
    "            docs[str(idx)]['content'] = stemmed_tokens\n",
    "            tokens += stemmed_tokens\n",
    "            counter += 1\n",
    "            # print progress\n",
    "            if counter % 1000 == 0:\n",
    "                print(counter, ' docs processed')\n",
    "        # save top k frequent\n",
    "        self.top_k = self.Top_K_Frequent(tokens, k)\n",
    "        # remove stop words from doc tokens\n",
    "        for doc_id, doc_content in docs.items():\n",
    "            docs[doc_id]['content'] = [token for token in doc_content['content'] if token not in self.top_k]\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6320f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:24:05.203631Z",
     "start_time": "2024-06-28T22:24:05.190469Z"
    }
   },
   "outputs": [],
   "source": [
    "global preprocessor\n",
    "preprocessor = DataPreprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fda444-3ecf-44ca-bf3d-06086add192a",
   "metadata": {},
   "source": [
    "### Load and Preprocess Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5a3995-71fd-41f8-bd3e-0a38c00548a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:24:07.689905100Z",
     "start_time": "2024-06-28T22:24:06.855009800Z"
    }
   },
   "outputs": [],
   "source": [
    "docs, contents, urls, articles = read_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0085caf-1bf8-40fc-a3ff-be0f921c7505",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:26:19.262711900Z",
     "start_time": "2024-06-28T22:24:08.318652500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  docs processed\n",
      "2000  docs processed\n",
      "3000  docs processed\n",
      "4000  docs processed\n",
      "5000  docs processed\n",
      "6000  docs processed\n",
      "7000  docs processed\n",
      "8000  docs processed\n",
      "9000  docs processed\n",
      "10000  docs processed\n",
      "11000  docs processed\n",
      "12000  docs processed\n"
     ]
    }
   ],
   "source": [
    "pre_processed_docs = preprocessor.preprocess(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a918bf-8cef-45d3-a5a1-40891d55096f",
   "metadata": {},
   "source": [
    "### Print Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06bb5f1c-4d1b-46ed-a767-c223410680bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:26:24.791020Z",
     "start_time": "2024-06-28T22:26:24.752317600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: و, Count: 219205\n",
      "Token: در, Count: 164334\n",
      "Token: به, Count: 133277\n",
      "Token: از, Count: 92933\n",
      "Token: این, Count: 82977\n",
      "Token: که, Count: 76240\n",
      "Token: با, Count: 68996\n",
      "Token: را, Count: 67490\n",
      "Token: اس, Count: 45541\n",
      "Token: کرد&کن, Count: 45104\n",
      "Token: برای, Count: 31022\n",
      "Token: داشت&دار, Count: 30052\n",
      "Token: تیم, Count: 27692\n",
      "Token: شد&شو, Count: 26688\n",
      "Token: ان, Count: 26332\n",
      "Token: کرد, Count: 22938\n",
      "Token: هم, Count: 22393\n",
      "Token: کشور, Count: 21730\n",
      "Token: ما, Count: 19717\n",
      "Token: یک, Count: 18733\n",
      "Token: بود&باش, Count: 18275\n",
      "Token: بازی, Count: 17796\n",
      "Token: باید, Count: 16196\n",
      "Token: تا, Count: 15870\n",
      "Token: بر, Count: 15685\n",
      "Token: شد, Count: 15641\n",
      "Token: وی, Count: 15486\n",
      "Token: داد&ده, Count: 14849\n",
      "Token: خود, Count: 14552\n",
      "Token: مجلس, Count: 14520\n",
      "Token: اسلامی, Count: 14415\n",
      "Token: گزارش, Count: 14040\n",
      "Token: فارس, Count: 13969\n",
      "Token: گفت, Count: 13773\n",
      "Token: مردم, Count: 13201\n",
      "Token: پیام, Count: 13112\n",
      "Token: رییس, Count: 12793\n",
      "Token: ایران, Count: 12717\n",
      "Token: خبرگزاری, Count: 12429\n",
      "Token: انتهای, Count: 12250\n",
      "Token: دولت, Count: 12236\n",
      "Token: اما, Count: 12211\n",
      "Token: سال, Count: 11955\n",
      "Token: گرفت&گیر, Count: 11845\n",
      "Token: توانست&توان, Count: 11059\n",
      "Token: بازیکن, Count: 11023\n",
      "Token: داشت&دارد, Count: 10782\n",
      "Token: ملی, Count: 10235\n",
      "Token: اینکه, Count: 10051\n",
      "Token: کار, Count: 9738\n"
     ]
    }
   ],
   "source": [
    "preprocessor.print_top_k()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffaa088-c816-4f61-965a-4c1e451b694b",
   "metadata": {},
   "source": [
    "### Example of Preprocessed Doc Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d85503fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:26:28.443418500Z",
     "start_time": "2024-06-28T22:26:28.421211100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'اعلام زمان قرعه کشی جام باشگاه های فوتسال آسیا',\n",
       " 'content': ['کنفدراسیون',\n",
       "  'فوتبال',\n",
       "  'اسیا',\n",
       "  'AFC',\n",
       "  'نامه',\n",
       "  'رسمی',\n",
       "  'فدراسیون',\n",
       "  'فوتبال',\n",
       "  'باشگاه',\n",
       "  'گیتی',\n",
       "  'پسند',\n",
       "  'زمان',\n",
       "  'قرعه',\n",
       "  'کشید&کش',\n",
       "  'جام',\n",
       "  'باشگاه',\n",
       "  'فوتسال',\n",
       "  'اسیا',\n",
       "  'رسما',\n",
       "  'اعلام',\n",
       "  'اساس',\n",
       "  '۲۵',\n",
       "  'فروردین',\n",
       "  'ماه',\n",
       "  '۱۴۰۱',\n",
       "  'مراسم',\n",
       "  'قرعه',\n",
       "  'کشید&کش',\n",
       "  'جام',\n",
       "  'باشگاه',\n",
       "  'فوتسال',\n",
       "  'اسیا',\n",
       "  'مالزی',\n",
       "  'برگزار',\n",
       "  'باشگاه',\n",
       "  'گیتی',\n",
       "  'پسند',\n",
       "  'بعنوان',\n",
       "  'قهرمان',\n",
       "  'فوتسال',\n",
       "  '۱۴۰۰',\n",
       "  'مسابقات',\n",
       "  'راه',\n",
       "  'پیدا',\n",
       "  'کرده_است',\n",
       "  'پیش',\n",
       "  'گیتی',\n",
       "  'پسند',\n",
       "  'تجربه',\n",
       "  '۳',\n",
       "  'دوره',\n",
       "  'حضور',\n",
       "  'جام',\n",
       "  'باشگاه',\n",
       "  'فوتسال',\n",
       "  'اسیا',\n",
       "  'داشته',\n",
       "  'هر',\n",
       "  'سه',\n",
       "  'دوره',\n",
       "  'فینال',\n",
       "  'مسابقات',\n",
       "  'راه',\n",
       "  'پیدا',\n",
       "  'کرده',\n",
       "  'عنوان',\n",
       "  'قهرمانی',\n",
       "  'دو',\n",
       "  'مقام',\n",
       "  'دومی',\n",
       "  'بدست',\n",
       "  'اورده'],\n",
       " 'url': 'https://www.farsnews.ir/news/14001224001005/اعلام-زمان-قرعه-کشی-جام-باشگاه-های-فوتسال-آسیا'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_docs['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665533c3-b2d5-4dab-a342-cc79a9703e91",
   "metadata": {},
   "source": [
    "## Positional Inverted Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe80d8441446dd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:26:30.310027Z",
     "start_time": "2024-06-28T22:26:30.285394900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def positional_inverted_index(docs):\n",
    "    p_inverted_index = {}\n",
    "    for index in docs:\n",
    "        for position, term in enumerate(docs[index]['content']):\n",
    "            # if its not a new term\n",
    "            if term in p_inverted_index:\n",
    "                # if the doc has already been in posting list of that term\n",
    "                if index in p_inverted_index[term]['docs']:\n",
    "                    p_inverted_index[term]['docs'][index]['positions'].append(position)\n",
    "                    p_inverted_index[term]['docs'][index]['tf_td'] += 1 # tf_td is term frequency of t in d\n",
    "                else:\n",
    "                    p_inverted_index[term]['doc_freq'] += 1\n",
    "                    p_inverted_index[term]['docs'][index] = { \n",
    "                                                    'positions': [position],\n",
    "                                                    'tf_td': 1\n",
    "                                                    }\n",
    "                p_inverted_index[term]['collection_frequency'] += 1\n",
    "                \n",
    "            # add term to dictionary if its new\n",
    "            else:\n",
    "                p_inverted_index[term] = {\n",
    "                 'doc_freq': 1,\n",
    "                 'collection_frequency': 1,\n",
    "                 'docs': {  # Postings list\n",
    "                       index: {\n",
    "                           'positions': [position],\n",
    "                           'tf_td': 1\n",
    "                           }\n",
    "                    }\n",
    "                }\n",
    "    return p_inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7500499467b1a654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:26:37.214381800Z",
     "start_time": "2024-06-28T22:26:31.508488700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "p_inverted_index = positional_inverted_index(pre_processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "320eb992ae96c0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:26:38.728057500Z",
     "start_time": "2024-06-28T22:26:38.704566200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50182\n"
     ]
    }
   ],
   "source": [
    "print(len(p_inverted_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89f04947dcb6520e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:10.654545200Z",
     "start_time": "2024-06-28T22:27:10.520436800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('گفتتیم', 1), ('۳۸۲', 1), ('النا', 1), ('کنندالبته', 1), ('نواقصات', 1), ('اندیشیده_شد', 1), ('شیردختران', 1), ('فوتبالاسامی', 1), ('ذهبی', 1), ('نیافرد', 1), ('شیخ\\u200cبهایی', 1), ('مزروعی', 1), ('تنیس\\u200cباز', 1), ('شن\\u200cریزی', 1), ('مانفیلس', 1), ('تنیس\\u200cبازان', 1), ('کرگیوس', 1), ('تسیتسیپاس', 1), ('بروکسبی', 1), ('۶۸۹', 1)]\n",
      "[('انتوان', 3), ('کاراسکو', 3), ('کیفی\\u200cسازی', 3), ('استهمه', 3), ('ببند', 3), ('توانایی\\u200cاش', 3), ('حزباوی', 3), ('گیلکی', 3), ('پورعروجی', 3), ('بازگردید', 3), ('لایک', 3), ('۴۶۹', 3), ('تبریزمس', 3), ('تهرانقشقایی', 3), ('پیونگ\\u200cچانگ', 3), ('دوطرف', 3), ('امستردام', 3), ('یایونده', 3), ('خالیست', 3), ('ایگالو', 3)]\n"
     ]
    }
   ],
   "source": [
    "tdf = []\n",
    "for term in p_inverted_index:\n",
    "    tdf += [(term, p_inverted_index[term]['collection_frequency'])]\n",
    "sorted_tdf = sorted(tdf, key=lambda x: x[1])\n",
    "print(sorted_tdf[:20])\n",
    "print(sorted_tdf[30000:30020])\n",
    "# print(sorted_tdf[:-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b9521aa18f90b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:16.250427500Z",
     "start_time": "2024-06-28T22:27:16.219385800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8188"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_inverted_index['فوتبال']['collection_frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdb7313c7995fd1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:17.903096600Z",
     "start_time": "2024-06-28T22:27:17.852782700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_freq': 2,\n",
       " 'collection_frequency': 3,\n",
       " 'docs': {'2645': {'positions': [401], 'tf_td': 1},\n",
       "  '8272': {'positions': [778, 850], 'tf_td': 2}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_inverted_index['ببند']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3d5fb2e4304dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Documents' Vectors & Champions list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447729a77cf2fe5b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Creating Documents' Vectors and also adding tf_idf score in positional inverted index for each document d in postings list of term t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5ed0366a6b89ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:21.791484Z",
     "start_time": "2024-06-28T22:27:21.787071200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12202\n"
     ]
    }
   ],
   "source": [
    "N = len(pre_processed_docs)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aee9f6827f49ecca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:23.743748300Z",
     "start_time": "2024-06-28T22:27:23.724292500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This function calculates tf_idf and add it to p_inverted_index, creates documents' vectors, and creates champions lists\n",
    "def calculate_doc_tf_idf(p_inverted_index, N, champ_len): # N is number of documents\n",
    "    docs_vectors = {}\n",
    "    \n",
    "    for term in p_inverted_index:\n",
    "        term_docs = dict(p_inverted_index[term]['docs'])  # term_docs is actually postings list of the term\n",
    "        df_t = p_inverted_index[term]['doc_freq']\n",
    "        # calculating tf_idf for each doc in postings list\n",
    "        for doc in p_inverted_index[term]['docs']:\n",
    "            tf = p_inverted_index[term]['docs'][doc]['tf_td']\n",
    "            w_td = (np.log10( N / df_t )) * (1 + np.log10(tf))\n",
    "            p_inverted_index[term]['docs'][doc]['tf_idf'] = w_td\n",
    "            \n",
    "            # add weight of this term to docs vector for future usages in query processing\n",
    "            if doc not in docs_vectors:\n",
    "                docs_vectors[doc] = {}\n",
    "            docs_vectors[doc][term] = {'tf_idf':w_td,'tf':tf}\n",
    "\n",
    "            \n",
    "        # sort postings list and put it in champions list of each term\n",
    "        sorted_term_docs = sorted(term_docs, key=lambda doc: term_docs[doc]['tf_td'], reverse=True)\n",
    "        p_inverted_index[term]['champions_list'] = {}\n",
    "        for doc_number in sorted_term_docs[:champ_len] if champ_len < df_t else sorted_term_docs:\n",
    "            p_inverted_index[term]['champions_list'][doc_number] = {\n",
    "                'tf_td': p_inverted_index[term]['docs'][doc_number]['tf_td'],\n",
    "                'tf_idf' : p_inverted_index[term]['docs'][doc_number]['tf_idf']\n",
    "            }\n",
    "       \n",
    "    return p_inverted_index, docs_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d80c4deb1db611d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:30.613530300Z",
     "start_time": "2024-06-28T22:27:25.239181400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "champ_len = 20\n",
    "p_inverted_index, docs_vectors = calculate_doc_tf_idf(p_inverted_index, N, champ_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24838658395b58",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3642553430ebf6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:32.863323600Z",
     "start_time": "2024-06-28T22:27:32.842369400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ماه': {'tf_idf': 0.7600951597276173, 'tf': 1},\n",
       " 'مراسم': {'tf_idf': 1.2864016614122344, 'tf': 1},\n",
       " 'برگزار': {'tf_idf': 0.8213161665267152, 'tf': 2},\n",
       " 'عنوان': {'tf_idf': 0.4918175114962707, 'tf': 1},\n",
       " 'مقام': {'tf_idf': 1.11330316705667, 'tf': 1},\n",
       " 'جوان': {'tf_idf': 0.938136923221623, 'tf': 1},\n",
       " 'برتر': {'tf_idf': 1.0520033409128284, 'tf': 2},\n",
       " 'سازمان': {'tf_idf': 0.8321246883250831, 'tf': 1},\n",
       " 'سوم': {'tf_idf': 1.0765553869442086, 'tf': 1},\n",
       " 'زیر': {'tf_idf': 0.805625092262702, 'tf': 1},\n",
       " 'برنامه': {'tf_idf': 0.6990411943176393, 'tf': 1},\n",
       " 'ورزش': {'tf_idf': 1.1264361823279525, 'tf': 1},\n",
       " 'امور': {'tf_idf': 1.012712670310246, 'tf': 1},\n",
       " 'پذیرفت&پذیر': {'tf_idf': 1.3192751545741883, 'tf': 1},\n",
       " 'رقابت': {'tf_idf': 0.8514078611611452, 'tf': 1},\n",
       " 'نه': {'tf_idf': 0.9802401233929534, 'tf': 1},\n",
       " 'میزبانی': {'tf_idf': 1.4060955072418055, 'tf': 1},\n",
       " 'نیرو': {'tf_idf': 1.2498013704060005, 'tf': 2},\n",
       " 'خانواده': {'tf_idf': 1.2189635327973172, 'tf': 1},\n",
       " 'علی': {'tf_idf': 0.9135363229041925, 'tf': 1},\n",
       " 'همین': {'tf_idf': 0.6294580070205508, 'tf': 1},\n",
       " 'دفاع': {'tf_idf': 1.0514017384540006, 'tf': 1},\n",
       " 'یکشنبه': {'tf_idf': 1.2171993009253925, 'tf': 1},\n",
       " 'اقدام': {'tf_idf': 0.8787966532674072, 'tf': 1},\n",
       " 'سطح': {'tf_idf': 1.511994266220354, 'tf': 2},\n",
       " 'پنج': {'tf_idf': 1.4274661779919338, 'tf': 1},\n",
       " 'تفکر': {'tf_idf': 1.7153631583846325, 'tf': 1},\n",
       " 'تربیت': {'tf_idf': 1.5549521036141136, 'tf': 1},\n",
       " 'فردا': {'tf_idf': 1.1424421455825968, 'tf': 1},\n",
       " 'اکبر': {'tf_idf': 1.8053976534086411, 'tf': 1},\n",
       " 'معرفی': {'tf_idf': 1.1960100018554545, 'tf': 1},\n",
       " 'سرباز': {'tf_idf': 3.638507480652689, 'tf': 12},\n",
       " 'داری': {'tf_idf': 1.9191136859081925, 'tf': 1},\n",
       " 'نخبه': {'tf_idf': 2.0485337348429424, 'tf': 2},\n",
       " 'وظیفه': {'tf_idf': 1.320018173543969, 'tf': 1},\n",
       " 'حضرت': {'tf_idf': 1.2603562179555423, 'tf': 1},\n",
       " 'سپاه': {'tf_idf': 1.949879747487523, 'tf': 2},\n",
       " 'خواهند_شد': {'tf_idf': 1.8384577542945622, 'tf': 1},\n",
       " 'بهمن': {'tf_idf': 1.1921149579719303, 'tf': 1},\n",
       " 'جشنواره': {'tf_idf': 2.957914676553486, 'tf': 2},\n",
       " 'شناخت&شناس': {'tf_idf': 1.4341846796530455, 'tf': 1},\n",
       " 'بدنی': {'tf_idf': 1.9191136859081925, 'tf': 1},\n",
       " 'برجسته': {'tf_idf': 1.858544316042695, 'tf': 1},\n",
       " 'فرهنگی': {'tf_idf': 1.0748605770590904, 'tf': 1},\n",
       " 'گانه': {'tf_idf': 2.0735937959511963, 'tf': 1},\n",
       " 'محور': {'tf_idf': 1.412489022022281, 'tf': 1},\n",
       " 'دین': {'tf_idf': 1.653461729781963, 'tf': 1},\n",
       " 'ذکر': {'tf_idf': 1.5524049146002337, 'tf': 1},\n",
       " 'امنیت': {'tf_idf': 1.2469529732821703, 'tf': 1},\n",
       " 'چهاردهمین': {'tf_idf': 2.706219778944763, 'tf': 1},\n",
       " 'اقتدار': {'tf_idf': 1.592276426637926, 'tf': 1},\n",
       " 'شایان': {'tf_idf': 2.1419483485062, 'tf': 1},\n",
       " 'ع': {'tf_idf': 1.77680085323047, 'tf': 1},\n",
       " 'مسلح': {'tf_idf': 1.56660302688065, 'tf': 1},\n",
       " 'فناوری': {'tf_idf': 1.4459495836859468, 'tf': 1},\n",
       " 'بسیج': {'tf_idf': 1.8709735194825312, 'tf': 2},\n",
       " 'تجلیل': {'tf_idf': 2.018245158910207, 'tf': 1},\n",
       " 'پاسداشت': {'tf_idf': 2.5066474240395586, 'tf': 1},\n",
       " 'هنری': {'tf_idf': 2.0735937959511963, 'tf': 1},\n",
       " 'ابتکار': {'tf_idf': 2.157012094942076, 'tf': 1},\n",
       " 'فداکاری': {'tf_idf': 2.1179480721024335, 'tf': 1},\n",
       " 'خلاقیت': {'tf_idf': 2.3155790090142245, 'tf': 1},\n",
       " 'بسیجی': {'tf_idf': 1.928068528561119, 'tf': 1},\n",
       " 'تبلیغاتی': {'tf_idf': 2.177946001777719, 'tf': 1},\n",
       " 'بصیرت': {'tf_idf': 1.861121738930506, 'tf': 1},\n",
       " 'مستضعف': {'tf_idf': 1.8409183528422188, 'tf': 1},\n",
       " 'سازندگی': {'tf_idf': 2.0778308488944512, 'tf': 1},\n",
       " 'مسولیت': {'tf_idf': 3.38746101632035, 'tf': 1},\n",
       " 'ایثارگری': {'tf_idf': 2.5066474240395586, 'tf': 1}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_vectors['8535']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c333435303d2aebd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:33.855643200Z",
     "start_time": "2024-06-28T22:27:33.835097600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2976': {'tf_td': 35, 'tf_idf': 3.946197821263585},\n",
       " '3209': {'tf_td': 27, 'tf_idf': 3.7713780534017833},\n",
       " '3371': {'tf_td': 24, 'tf_idf': 3.6920334882741845},\n",
       " '11741': {'tf_td': 23, 'tf_idf': 3.6633631956531896},\n",
       " '10532': {'tf_td': 20, 'tf_idf': 3.5692125356931492},\n",
       " '3005': {'tf_td': 18, 'tf_idf': 3.4982364036050075},\n",
       " '3550': {'tf_td': 18, 'tf_idf': 3.4982364036050075},\n",
       " '3145': {'tf_td': 14, 'tf_idf': 3.328938389581892},\n",
       " '5776': {'tf_td': 13, 'tf_idf': 3.2790155395699467},\n",
       " '3341': {'tf_td': 9, 'tf_idf': 3.0312976691390547},\n",
       " '3818': {'tf_td': 9, 'tf_idf': 3.0312976691390547},\n",
       " '8325': {'tf_td': 9, 'tf_idf': 3.0312976691390547},\n",
       " '3633': {'tf_td': 8, 'tf_idf': 2.9519531040114564},\n",
       " '4122': {'tf_td': 8, 'tf_idf': 2.9519531040114564},\n",
       " '4450': {'tf_td': 8, 'tf_idf': 2.9519531040114564},\n",
       " '4998': {'tf_td': 8, 'tf_idf': 2.9519531040114564},\n",
       " '5330': {'tf_td': 8, 'tf_idf': 2.9519531040114564},\n",
       " '11032': {'tf_td': 8, 'tf_idf': 2.9519531040114564},\n",
       " '3093': {'tf_td': 7, 'tf_idf': 2.8619996551159392},\n",
       " '3269': {'tf_td': 7, 'tf_idf': 2.8619996551159392}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_inverted_index['ازمون']['champions_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9629edface86372d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:35.002182700Z",
     "start_time": "2024-06-28T22:27:34.985330200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_freq': 2,\n",
       " 'collection_frequency': 3,\n",
       " 'docs': {'2645': {'positions': [401],\n",
       "   'tf_td': 1,\n",
       "   'tf_idf': 3.7854010249923875},\n",
       "  '8272': {'positions': [778, 850], 'tf_td': 2, 'tf_idf': 4.924920279132276}},\n",
       " 'champions_list': {'8272': {'tf_td': 2, 'tf_idf': 4.924920279132276},\n",
       "  '2645': {'tf_td': 1, 'tf_idf': 3.7854010249923875}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_inverted_index['ببند']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c973c",
   "metadata": {},
   "source": [
    "# Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "420a1498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:36.829197500Z",
     "start_time": "2024-06-28T22:27:36.814303300Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_query_tf_idf(tf_tq, N, df_t):\n",
    "    tf = 1 + np.log10(tf_tq)\n",
    "    idf = np.log10(N / df_t)\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eafd3eaa-2d76-493c-9418-6b2782ce2615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:37.491925400Z",
     "start_time": "2024-06-28T22:27:37.459589600Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def vector_length(vector_dict):\n",
    "    length = math.sqrt(sum(tf_idf_value['tf_idf'] ** 2 for tf_idf_value in vector_dict.values()))\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79503b9e35003da7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Calculating cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c0bc8eb64f4e947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:39.049038900Z",
     "start_time": "2024-06-28T22:27:39.021433700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def query_scoring(query, total_number_of_docs, p_inverted_index, k, champions_list = False):\n",
    "    cosine_scores = {}\n",
    "    query_tokens = preprocessor.simple_preprocess(query)\n",
    "    query_tokens_count = dict(Counter(query_tokens))    \n",
    "    print(query_tokens_count)\n",
    "\n",
    "    for term in query_tokens_count:\n",
    "        if term in p_inverted_index:\n",
    "            if champions_list and k <= champ_len: \n",
    "                term_docs = p_inverted_index[term]['champions_list']\n",
    "            else:\n",
    "                term_docs = p_inverted_index[term]['docs']\n",
    "            df_t = p_inverted_index[term]['doc_freq']\n",
    "            w_tq = calculate_query_tf_idf(query_tokens_count[term], total_number_of_docs, df_t)\n",
    "            for doc in term_docs:\n",
    "                w_td = term_docs[doc]['tf_idf']\n",
    "                # update doc scores for cosines similarity\n",
    "                if int(doc) in cosine_scores:\n",
    "                    # update doc scores for cosines similarity\n",
    "                    cosine_scores[int(doc)] += w_td * w_tq\n",
    "                else:\n",
    "                    cosine_scores[int(doc)] = w_td * w_tq\n",
    "    # calculate cosine score by dividing by doc vector length\n",
    "    for doc_number in cosine_scores:\n",
    "        cosine_scores[doc_number] /= vector_length(docs_vectors[str(doc_number)])\n",
    "    # sort scores for top k \n",
    "    sorted_doc_cosine = sorted(cosine_scores.items(), key=lambda x:x[1], reverse=True)\n",
    "    return sorted_doc_cosine[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440a85e56ca2d43",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86d7a132c8d1bf08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:40.525638600Z",
     "start_time": "2024-06-28T22:27:40.514904800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    dict_result = {}\n",
    "    for rank, result in enumerate(results):\n",
    "        # print(f'my\\n {result}')\n",
    "        doc_id = result[0]\n",
    "        if doc_id is None:\n",
    "            continue\n",
    "        print(100*'-' + '\\n')\n",
    "        print(f'Rank: {rank + 1}')\n",
    "        print(f'Score: {result[1]}')\n",
    "        print(f'ID: {doc_id}')\n",
    "        print(f'{docs[f\"{doc_id}\"][\"title\"]}')\n",
    "        print(f'{docs[f\"{doc_id}\"][\"url\"]}')\n",
    "        dict_result[rank + 1] = {'docID': doc_id,\n",
    "                                 'title': docs[str(doc_id)][\"title\"],\n",
    "                                 'url'  : docs[str(doc_id)][\"url\"]}\n",
    "    return dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2d46d19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:41.726791800Z",
     "start_time": "2024-06-28T22:27:41.710761Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def query_search(query, result_numbers = 5, champion_list = False):\n",
    "    start = time.time()\n",
    "    results = query_scoring(query, N, p_inverted_index, result_numbers, champion_list)\n",
    "    end = time.time()\n",
    "    print(f'Time: {end - start}')\n",
    "    if len(results) == 0:\n",
    "        print(\"نتیجه ای یافت نشد\")\n",
    "    else:\n",
    "        print(\"Cosine Scores:\")\n",
    "        print(100*'=')\n",
    "        return print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e969d324b0122b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:45.065891200Z",
     "start_time": "2024-06-28T22:27:44.895914600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'وزیر': 1}\n",
      "Time: 0.20999789237976074\n",
      "Cosine Scores:\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 1\n",
      "Score: 0.14329647678742605\n",
      "ID: 12191\n",
      "آغاز نشست غیرعلنی مجلس با حضور امیرعبداللهیان\n",
      "https://www.farsnews.ir/news/14000724000697/آغاز-نشست-غیرعلنی-مجلس-با-حضور-امیرعبداللهیان\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 2\n",
      "Score: 0.13972084497123127\n",
      "ID: 10893\n",
      "زارعی کوشا استاندار کردستان شد\n",
      "https://www.farsnews.ir/news/14000826000505/زارعی-کوشا-استاندار-کردستان-شد\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 3\n",
      "Score: 0.1373662946239786\n",
      "ID: 10640\n",
      "جزئیات برگزاری جلسه رأی اعتماد به وزیر پیشنهادی آموزش و پرورش\n",
      "https://www.farsnews.ir/news/14000904000549/جزئیات-برگزاری-جلسه-رأی-اعتماد-به-وزیر-پیشنهادی-آموزش-و-پرورش\n"
     ]
    }
   ],
   "source": [
    "r1 = query_search('وزیر', result_numbers= 3, champion_list= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfac58cb1f66be45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T22:27:49.309419Z",
     "start_time": "2024-06-28T22:27:49.255433400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'وزیر': 1}\n",
      "Time: 0.02099752426147461\n",
      "Cosine Scores:\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 1\n",
      "Score: 0.05450334231579835\n",
      "ID: 10268\n",
      "دستور کار کمیسیون‌های مجلس/ دیدار نمایندگان با وزیر خارجه و بررسی تخلفات روحانی و زنگنه در انعقاد قرارداد کرسنت\n",
      "https://www.farsnews.ir/news/14000910000920/دستور-کار-کمیسیون‌های-مجلس-دیدار-نمایندگان-با-وزیر-خارجه-و-بررسی\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 2\n",
      "Score: 0.05054510548588114\n",
      "ID: 10890\n",
      "سومین وزیر پیشنهادی آموزش و پرورش در ایستگاه بهارستان/ از سرعت عمل رئیس جمهور در معرفی تا گزینه‌ای از بدنه فرهنگیان\n",
      "https://www.farsnews.ir/news/14000826000559/سومین-وزیر-پیشنهادی-آموزش-و-پرورش-در-ایستگاه-بهارستان-از-سرعت-عمل\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 3\n",
      "Score: 0.0477964222342544\n",
      "ID: 7478\n",
      "اصلاحات بدون رتوش| مروری بر بدزبانی‌ها و اهانت‌های دولت روحانی به مردم و خبرنگاران\n",
      "https://www.farsnews.ir/news/14001203000851/اصلاحات-بدون-رتوش|-مروری-بر-بدزبانی‌ها-و-اهانت‌های-دولت-روحانی-به-مردم\n"
     ]
    }
   ],
   "source": [
    "r1c = query_search('وزیر', result_numbers= 3, champion_list= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26f8509bb7aa3726",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'سازمان': 1, 'لیگ': 1}\n",
      "Time: 0.38475990295410156\n",
      "Cosine Scores:\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 1\n",
      "Score: 0.19017963053603698\n",
      "ID: 2\n",
      "محل برگزاری نشست‌های خبری سرخابی‌ها؛ مجیدی در سازمان لیگ، گل‌محمدی در تمرین پرسپولیس\n",
      "https://www.farsnews.ir/news/14001224000971/محل-برگزاری-نشست‌های-خبری-سرخابی‌ها-مجیدی-در-سازمان-لیگ-گل‌محمدی-در\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 2\n",
      "Score: 0.17547625862038246\n",
      "ID: 2607\n",
      "دیدار حساس لیگ برتر فوتسال لغو شد\n",
      "https://www.farsnews.ir/news/14001119000691/دیدار-حساس-لیگ-برتر-فوتسال-لغو-شد\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 3\n",
      "Score: 0.17091165680175882\n",
      "ID: 3789\n",
      "دیدار هوادار و استقلال لغو شد\n",
      "https://www.farsnews.ir/news/14001104000380/دیدار-هوادار-و-استقلال-لغو-شد\n"
     ]
    }
   ],
   "source": [
    "r2 = query_search('سازمان لیگ', result_numbers= 3, champion_list= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d28c456920a18d2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'کریسمس': 1}\n",
      "Time: 0.017000198364257812\n",
      "Cosine Scores:\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 1\n",
      "Score: 0.8669566044973201\n",
      "ID: 5933\n",
      "ستاره اسپانیایی؛ هدیه کریسمس گواردیولا به ژاوی+عکس\n",
      "https://www.farsnews.ir/news/14001007000739/ستاره-اسپانیایی-هدیه-کریسمس-گواردیولا-به-ژاوی-عکس\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 2\n",
      "Score: 0.7741970328238605\n",
      "ID: 6117\n",
      "کی‌روش «دیکتاتور» لقب گرفت/اختلاف مرد پرتغالی با مصری‌ها به خاطر کریسمس+عکس\n",
      "https://www.farsnews.ir/news/14001005000165/کی‌روش-دیکتاتور-لقب-گرفت-اختلاف-مرد-پرتغالی-با-مصری‌ها-به-خاطر-کریسمس\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 3\n",
      "Score: 0.7332855143304998\n",
      "ID: 6120\n",
      "کشتار در ورزشگاه فوتبال در آستانه سال جدید\n",
      "https://www.farsnews.ir/news/14001005000143/کشتار-در-ورزشگاه-فوتبال-در-آستانه-سال-جدید\n"
     ]
    }
   ],
   "source": [
    "r3 = query_search('کریسمس',result_numbers= 3, champion_list= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "836577122a727f8b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0864310206563688 0.2808929144034299 36\n"
     ]
    }
   ],
   "source": [
    "tf_idf_dc = p_inverted_index['کریسمس']['docs']['5933']['tf_idf']\n",
    "score_d = tf_idf_dc / vector_length(docs_vectors['5933'])\n",
    "print(tf_idf_dc, score_d, len(docs['5933']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed2999388e6f857c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.559032861837624 0.25083892289911525 129\n"
     ]
    }
   ],
   "source": [
    "tf_idf_dc2 = p_inverted_index['کریسمس']['docs']['6117']['tf_idf']\n",
    "score_d2 = tf_idf_dc2 / vector_length(docs_vectors['6117'])\n",
    "print(tf_idf_dc2, score_d2, len(docs['6117']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e26d1d39a12025a0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'کریسمس': 1}\n",
      "Time: 0.01399993896484375\n",
      "Cosine Scores:\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 1\n",
      "Score: 0.8669566044973201\n",
      "ID: 5933\n",
      "ستاره اسپانیایی؛ هدیه کریسمس گواردیولا به ژاوی+عکس\n",
      "https://www.farsnews.ir/news/14001007000739/ستاره-اسپانیایی-هدیه-کریسمس-گواردیولا-به-ژاوی-عکس\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 2\n",
      "Score: 0.7741970328238605\n",
      "ID: 6117\n",
      "کی‌روش «دیکتاتور» لقب گرفت/اختلاف مرد پرتغالی با مصری‌ها به خاطر کریسمس+عکس\n",
      "https://www.farsnews.ir/news/14001005000165/کی‌روش-دیکتاتور-لقب-گرفت-اختلاف-مرد-پرتغالی-با-مصری‌ها-به-خاطر-کریسمس\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 3\n",
      "Score: 0.7332855143304998\n",
      "ID: 6120\n",
      "کشتار در ورزشگاه فوتبال در آستانه سال جدید\n",
      "https://www.farsnews.ir/news/14001005000143/کشتار-در-ورزشگاه-فوتبال-در-آستانه-سال-جدید\n"
     ]
    }
   ],
   "source": [
    "r3c = query_search('کریسمس',result_numbers= 3, champion_list= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15111747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'کمیسیون': 1, 'اجتهاد': 1}\n",
      "Time: 0.01900005340576172\n",
      "Cosine Scores:\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 1\n",
      "Score: 0.41093649508138524\n",
      "ID: 12141\n",
      "«ماموستا عبدالسلام کریمی» مشاور رئیس جمهور در امور اقوام و اقلیت‌های دینی و مذهبی شد\n",
      "https://www.farsnews.ir/news/14000725000846/ماموستا-عبدالسلام-کریمی-مشاور-رئیس-جمهور-در-امور-اقوام-و-اقلیت‌های\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 2\n",
      "Score: 0.2784609427492448\n",
      "ID: 9816\n",
      "تحقیر زن در اندیشه غرب\n",
      "https://www.farsnews.ir/news/14000923000557/تحقیر-زن-در-اندیشه-غرب\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 3\n",
      "Score: 0.2641584981329873\n",
      "ID: 12198\n",
      "نقدی بر یادداشت «مرزبندی گفتمانی با طالبان»/ وارونه‌نمایی گفتمانی اصلاح‌طلبان\n",
      "https://www.farsnews.ir/news/14000724000611/نقدی-بر-یادداشت-مرزبندی-گفتمانی-با-طالبان-وارونه‌نمایی-گفتمانی\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 4\n",
      "Score: 0.26117473596712976\n",
      "ID: 11935\n",
      "تفکر نهادسازی در اندیشه آیت‌الله مهدوی‌کنی و ایده ایشان برای تولید علوم انسانی اسلامی\n",
      "https://www.farsnews.ir/news/14000801000312/تفکر-نهادسازی-در-اندیشه-آیت‌الله-مهدوی‌کنی-و-ایده-ایشان-برای-تولید\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 5\n",
      "Score: 0.2178621620280343\n",
      "ID: 9241\n",
      "در سیزدهمین سفر استانی رئیس‌جمهور چه گذشت؟\n",
      "https://www.farsnews.ir/news/14001009000692/در-سیزدهمین-سفر-استانی-رئیس‌جمهور-چه-گذشت\n"
     ]
    }
   ],
   "source": [
    "r4 = query_search('کمیسیون اجتهاد', result_numbers = 5, champion_list = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74a09c4371516f3a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'جیانی': 1, 'اینفانتینو': 1}\n",
      "Time: 0.040000200271606445\n",
      "Cosine Scores:\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 1\n",
      "Score: 1.5289023053255142\n",
      "ID: 6731\n",
      "حضور مهدوی کیا در بازی نمادین ستارگان در ورزشگاه جام جهانی\n",
      "https://www.farsnews.ir/news/14000926000283/حضور-مهدوی-کیا-در-بازی-نمادین-ستارگان-در-ورزشگاه-جام-جهانی\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 2\n",
      "Score: 1.2640737943569136\n",
      "ID: 4033\n",
      "احتمال لغو سفر اینفانتینو به تهران/ وضعیت دستیاران اسپانیایی شمسایی بررسی می شود\n",
      "https://www.farsnews.ir/news/14001102000084/احتمال-لغو-سفر-اینفانتینو-به-تهران-وضعیت-دستیاران-اسپانیایی-شمسایی\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rank: 3\n",
      "Score: 0.9527225123123577\n",
      "ID: 3704\n",
      "تکذیب دیدار رئیس فیفا با رییسی\n",
      "https://www.farsnews.ir/news/14001105000360/تکذیب-دیدار-رئیس-فیفا-با-رییسی\n"
     ]
    }
   ],
   "source": [
    "r4 = query_search('جیانی اینفانتینو',result_numbers= 3, champion_list= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
